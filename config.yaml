train_objective: "mnr" # "mnr", "pair-class", "triplet"
run_name: "mnr_attentiv_last_8h_8q" # "triplet_max_pooling_bert"

datasets:
  mnli:
    name: "LysandreJik/glue-mnli-train"
  all-nli:
    name: "sentence-transformers/all-nli"
    subset: "pair-class" # "triplet"

training:
  batch_size: 32
  learning_rate: 2e-5
  epochs: 5
  pooling_learning_rate: 2e-5 # Used only in attention pooling


embedder:
  pooling: "attention_last_layer" # "mean", "max" , "attention_last_layer", "attention_multi_layer"


# Usedif there is attention pooling
heads: 8
queries_per_head: 8